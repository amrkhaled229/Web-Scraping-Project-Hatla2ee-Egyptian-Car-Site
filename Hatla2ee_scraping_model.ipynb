{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRLOVmSYcr1S",
        "outputId": "e0bbcbdf-2b67-46df-a711-9df2248d1a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "J2Z4aLyucqZo",
        "outputId": "23753c81-bf13-45c9-e9f3-5ff4d141bdef"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import re\n",
        "\n",
        "def get_soup(url):\n",
        "    retries = 5\n",
        "    backoff_factor = 1\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            response.raise_for_status()\n",
        "            return BeautifulSoup(response.content, 'html.parser')\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(backoff_factor * (2 ** attempt))\n",
        "                continue\n",
        "            else:\n",
        "                print(f\"Failed to retrieve {url}: {e}\")\n",
        "                return None\n",
        "\n",
        "def clean_text(text):\n",
        "    return re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "def extract_numeric_value(text):\n",
        "    numeric_value = re.findall(r'\\d+', text)\n",
        "    return int(numeric_value[0]) if numeric_value else None\n",
        "\n",
        "def preprocess_car_data(car):\n",
        "    title = clean_text(car.find('div', class_='newCarListUnit_header').find('a').text)\n",
        "    car_model_name = clean_text(car.find('div', class_='newCarListUnit_metaTags').find_all('span', class_='newCarListUnit_metaLink')[1].text)\n",
        "    car_color = clean_text(car.find('span', class_='newCarListUnit_metaTag mob_hidden').text)\n",
        "    car_mileage = \"\"\n",
        "    meta_tags = car.find_all('span', class_='newCarListUnit_metaTag')\n",
        "    for tag in meta_tags:\n",
        "        if \"كم\" in tag.text:\n",
        "            car_mileage = clean_text(tag.text)\n",
        "            break\n",
        "    car_mileage = extract_numeric_value(car_mileage)  \n",
        "    location = clean_text(car.find('div', class_='newCarListUnit_metaTags').find_all('span', class_='newCarListUnit_metaLink')[-1].text)\n",
        "    date = clean_text(car.find('div', class_='otherData_Date').find('span').text)\n",
        "    price = clean_text(car.find('div', class_='main_price').find('a').text)\n",
        "    price = extract_numeric_value(price)  \n",
        "    image = car.find('img', class_='lazy')['data-original']\n",
        "\n",
        "    return {\n",
        "        'title': title,\n",
        "        'car_model_name': car_model_name,\n",
        "        'car_color': car_color,\n",
        "        'car_mileage': car_mileage if car_mileage is not None else 0,  \n",
        "        'location': location,\n",
        "        'date': date,\n",
        "        'price': price if price is not None else 0, \n",
        "        'image': image\n",
        "    }\n",
        "\n",
        "def scrape_car_data(base_url, num_pages):\n",
        "    car_data = []\n",
        "\n",
        "    for page in range(1, num_pages + 1):\n",
        "        url = f\"{base_url}/page/{page}\"\n",
        "        soup = get_soup(url)\n",
        "\n",
        "        if soup is None:\n",
        "            continue\n",
        "\n",
        "        for car in soup.find_all('div', class_='newCarListUnit_wrap'):\n",
        "            car_details = preprocess_car_data(car)\n",
        "            car_data.append(car_details)\n",
        "\n",
        "        if len(car_data) >= 1000:\n",
        "            break\n",
        "\n",
        "    return car_data[:1000]\n",
        "\n",
        "def save_to_csv(data, filename):\n",
        "    with open(filename, mode='w', newline='', encoding='utf-8-sig') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=['title', 'car_model_name', 'car_color', 'car_mileage', 'location', 'date', 'price', 'image'])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "\n",
        "    print(f'Data has been written to {filename}')\n",
        "\n",
        "def download_csv(base_url, num_pages, filename):\n",
        "    data = scrape_car_data(base_url, num_pages)\n",
        "    save_to_csv(data, filename)\n",
        "\n",
        "base_url = 'https://eg.hatla2ee.com/ar/car/mercedes'\n",
        "num_pages = 50  \n",
        "csv_file = 'car_data.csv'\n",
        "\n",
        "download_csv(base_url, num_pages, csv_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iUy4Ooat17BH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKD3DkkU18qr",
        "outputId": "0f6216d5-f3b0-4e8c-df97-c3beb2097906"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "file_path = '/content/car_data.csv'\n",
        "car_data = pd.read_csv(file_path)\n",
        "\n",
        "def convert_to_numeric(value):\n",
        "    if isinstance(value, str):\n",
        "        return int(value.replace(',', '').replace(' كم', '').replace(' جنيه', '').replace('-', '0'))\n",
        "    return value\n",
        "\n",
        "car_data['car_mileage'] = car_data['car_mileage'].apply(convert_to_numeric)\n",
        "car_data['price'] = car_data['price'].apply(convert_to_numeric)\n",
        "\n",
        "car_data['model_year'] = car_data['title'].str.extract(r'(\\d{4})').astype(float)\n",
        "\n",
        "car_data = car_data.dropna(subset=['model_year'])\n",
        "\n",
        "car_data_encoded = pd.get_dummies(car_data, columns=['car_model_name', 'car_color', 'location'], drop_first=True)\n",
        "\n",
        "car_data_encoded = car_data_encoded.drop(columns=['title', 'date', 'image'])\n",
        "\n",
        "X = car_data_encoded.drop(columns=['price'])\n",
        "y = car_data_encoded['price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "numerical_features = ['car_mileage', 'model_year']\n",
        "categorical_features = [col for col in X_train.columns if col not in numerical_features]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', 'passthrough', categorical_features)])\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('model', RandomForestRegressor(random_state=42))])\n",
        "\n",
        "param_distributions = {\n",
        "    'model__n_estimators': [50, 100, 200],\n",
        "    'model__max_features': ['auto', 'sqrt'],\n",
        "    'model__max_depth': [10, 20, None],\n",
        "    'model__min_samples_split': [2, 5, 10],\n",
        "    'model__min_samples_leaf': [1, 2, 4],\n",
        "    'model__bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=50, cv=5,\n",
        "                                   verbose=2, random_state=42, n_jobs=-1)\n",
        "\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"R-squared (R²) Score:\", r2)\n",
        "\n",
        "\n",
        "sample_input = pd.DataFrame(columns=X_train.columns)\n",
        "\n",
        "sample_input.loc[0] = 0  \n",
        "sample_input['car_mileage'] = 50000  \n",
        "sample_input['model_year'] = 2020  \n",
        "sample_input['car_model_name_230'] = 1  \n",
        "sample_input['car_color_أسود'] = 1  \n",
        "sample_input['location_القاهرة'] = 1  \n",
        "\n",
        "\n",
        "predicted_price = random_search.predict(sample_input)\n",
        "print(\"Predicted Price:\", predicted_price[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R2FMGU_7W6g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
